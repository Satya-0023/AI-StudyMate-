const axios = require('axios');

const generateAIContent = async (topic, difficulty) => {
    // Mock Fallback Data (Structured to match schema)
    const getMockContent = (topic) => ({
        explanation: `(Offline Mode) The AI service is currently unavailable. This is a placeholder explanation for the topic: "${topic}". Please checks your HF_API_KEY and internet connection.`,
        quiz: [
            {
                question: "What is the status of the AI service?",
                options: ["Online", "Offline / Mock Mode", "Loading", "Unknown"],
                correct_answer: "Offline / Mock Mode"
            },
            {
                question: "Which key is required in .env?",
                options: ["API_KEY", "SECRET_TOKEN", "HF_API_KEY", "PASSCODE"],
                correct_answer: "HF_API_KEY"
            },
            {
                question: "What format does the backend expect?",
                options: ["XML", "JSON", "Plain Text", "HTML"],
                correct_answer: "JSON"
            },
            {
                question: "How many questions are in this mock quiz?",
                options: ["1", "3", "5", "10"],
                correct_answer: "5"
            },
            {
                question: "Is this content generated by a live model?",
                options: ["Yes", "No", "Maybe", "Ask again later"],
                correct_answer: "No"
            }
        ]
    });

    const apiKey = process.env.HF_API_KEY;

    // Immediate fallback if no key
    if (!apiKey) {
        console.warn('HF_API_KEY missing. Returning mock content.');
        return getMockContent(topic);
    }

    const systemPrompt = `You are an educational assistant.
Generate a JSON response for the topic: "${topic}" (Difficulty: ${difficulty}).
Format requirements:
1. "explanation": A clear, concise paragraph explaining the topic (approx 100-150 words).
2. "quiz": An array of exactly 5 multiple-choice questions.
3. Each question object must have:
   - "question": The question text.
   - "options": An array of 4 distinct text options.
   - "correct_answer": The exact text of the correct option (must match one of the options).

RETURN ONLY VALID JSON. NO MARKDOWN. NO PREAMBLE.
Example format:
{
  "explanation": "Photosynthesis is...",
  "quiz": [
    {
      "question": "Where does photosynthesis occur?",
      "options": ["Roots", "Stem", "Chloroplasts", "Bark"],
      "correct_answer": "Chloroplasts"
    }
  ]
}`;

    // Models to try in order
    const models = [
        'HuggingFaceH4/zephyr-7b-beta',
        'mistralai/Mistral-7B-Instruct-v0.2'
    ];

    for (const model of models) {
        try {
            console.log(`Attempting generation with model: ${model}`);

            // Construct prompt based on model (Zephyr/Mistral use similar chat templates)
            const prompt = `<|system|>
${systemPrompt}</s>
<|user|>
Generate content for topic: ${topic}</s>
<|assistant|>`;

            const response = await axios.post(
                `https://api-inference.huggingface.co/models/${model}`,
                {
                    inputs: prompt,
                    parameters: {
                        max_new_tokens: 1500,
                        return_full_text: false,
                        temperature: 0.7,
                        top_p: 0.95,
                        stop: ["</s>"]
                    }
                },
                {
                    headers: {
                        Authorization: `Bearer ${apiKey}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 45000 // 45s timeout
                }
            );

            let generatedText = '';
            if (Array.isArray(response.data) && response.data.length > 0) {
                generatedText = response.data[0].generated_text;
            } else if (typeof response.data === 'string') {
                generatedText = response.data;
            }

            if (!generatedText) throw new Error('Empty response from AI');

            // JSON Extraction
            const jsonStart = generatedText.indexOf('{');
            const jsonEnd = generatedText.lastIndexOf('}');

            if (jsonStart === -1 || jsonEnd === -1) {
                throw new Error('No JSON found in response');
            }

            const jsonStr = generatedText.substring(jsonStart, jsonEnd + 1);
            let content;

            try {
                content = JSON.parse(jsonStr);
            } catch (jsonErr) {
                // Try to sanitize common JSON errors (newlines in strings)
                const sanitized = jsonStr.replace(/\n/g, ' ');
                content = JSON.parse(sanitized);
            }

            // Validate Schema
            if (!content.explanation || !Array.isArray(content.quiz) || content.quiz.length === 0) {
                throw new Error('Invalid JSON schema');
            }

            // Normalization
            // Ensure 5 questions if possible, or just accept what we got
            // Ensure correct_answer matches an option
            content.quiz = content.quiz.map(q => {
                // If correct_answer isn't in options, try to fix or default
                if (!q.options.includes(q.correct_answer)) {
                    // Try to match partial
                    const match = q.options.find(o => o.includes(q.correct_answer) || q.correct_answer.includes(o));
                    if (match) q.correct_answer = match;
                    else q.correct_answer = q.options[0]; // Fallback
                }
                return q;
            });

            console.log(`Success with model: ${model}`);
            return content;

        } catch (error) {
            console.error(`Failed with ${model}:`, error.message);
            if (error.response) {
                console.error('Status:', error.response.status, 'Data:', error.response.data);

                // If 503 (Loading) or 429 (Rate Limit), we might want to wait and retry, 
                // but for now we proceed to next model or fallback.
            }
            // Continue to next model
        }
    }

    // If we reach here, all models failed
    console.warn('All AI models failed. Returning mock fallback.');
    return getMockContent(topic);
};

module.exports = { generateAIContent };
